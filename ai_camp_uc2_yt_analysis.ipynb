{
  "cells": [
    {
      "cell_type": "code",
      "id": "bUAxKkTqHifWXMSZdLuoN6Au",
      "metadata": {
        "tags": [],
        "id": "bUAxKkTqHifWXMSZdLuoN6Au"
      },
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uncovering the YouTube Moments that matter"
      ],
      "metadata": {
        "id": "oOlQsdSfMcB-"
      },
      "id": "oOlQsdSfMcB-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Laxmi Harikumar](https://github.com/laxmi-genai) |"
      ],
      "metadata": {
        "id": "d1VeQoOhMjk0"
      },
      "id": "d1VeQoOhMjk0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "[Gemini 2.0 Flash-Lite](https://cloud.google.com/vertex-ai/generative-ai/docs/gemini-v2#2.0-flash-lite) is a new multimodal generative ai model from the Gemini family developed by [Google DeepMind](https://deepmind.google/). It is Google's fastest and most cost efficient Flash model. It's an upgrade path for 1.5 Flash users who want better quality for the same price and speed.\n",
        "\n",
        "Gemini 2.0 Flash-Lite includes:\n",
        "\n",
        "- Multimodal input, text output\n",
        "- 1M token input context window\n",
        "- 8k token output context window\n",
        "\n",
        "### Pricing\n",
        "Information on the pricing for Gemini 2.0 Flash is available on our [Pricing page](https://cloud.google.com/vertex-ai/generative-ai/pricing).\n",
        "\n",
        "\n",
        "## Objective\n",
        "\n",
        "In this notebook, you'll explore how to do direct analysis of publicly available [YouTube](https://www.youtube.com/) videos with Gemini 2.0 Flash-Lite in GenAI SDK\n",
        "\n",
        "You will complete the following tasks:\n",
        "- Summarizing a single YouTube video using Gemini 1.5 Flash Lite\n",
        "- Identify the commercial entities appearing and record their timestamps."
      ],
      "metadata": {
        "id": "Lf3gSEMtZZjx"
      },
      "id": "Lf3gSEMtZZjx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started"
      ],
      "metadata": {
        "id": "UWP5bizFNFre"
      },
      "id": "UWP5bizFNFre"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Google Gen AI SDK for Python"
      ],
      "metadata": {
        "id": "iursWTdKNI0B"
      },
      "id": "iursWTdKNI0B"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet google-genai"
      ],
      "metadata": {
        "id": "3wgqzcEkNCyi"
      },
      "id": "3wgqzcEkNCyi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ],
      "metadata": {
        "id": "hmf_ChNTAaxC"
      },
      "id": "hmf_ChNTAaxC"
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "sh5OoODOAc5a"
      },
      "id": "sh5OoODOAc5a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>"
      ],
      "metadata": {
        "id": "G9VXok8MD5Qd"
      },
      "id": "G9VXok8MD5Qd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment."
      ],
      "metadata": {
        "id": "frkCOOt1NTgL"
      },
      "id": "frkCOOt1NTgL"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "tSraz2eANQkQ"
      },
      "id": "tSraz2eANQkQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect with GenAI SDK\n",
        "\n",
        "This notebook shows how to use the Google Gen AI SDK with the Vertex AI to build enterprise-ready projects on Google Cloud."
      ],
      "metadata": {
        "id": "6IMJJ0JmNW9p"
      },
      "id": "6IMJJ0JmNW9p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "IBQIvY-KNaVq"
      },
      "id": "IBQIvY-KNaVq"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display, HTML\n",
        "from google import genai\n",
        "from google.genai.types import (\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        "\n",
        ")\n",
        "import os"
      ],
      "metadata": {
        "id": "mYo9-iOBNavQ"
      },
      "id": "mYo9-iOBNavQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ],
      "metadata": {
        "id": "cyzARjWiNrJY"
      },
      "id": "cyzARjWiNrJY"
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")"
      ],
      "metadata": {
        "id": "vgif1xFONez0"
      },
      "id": "vgif1xFONez0",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "qjhh7tYRN6xi"
      },
      "id": "qjhh7tYRN6xi",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the Gemini 2.0 Flash-Lite model"
      ],
      "metadata": {
        "id": "Luk1oQ-JN47V"
      },
      "id": "Luk1oQ-JN47V"
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-lite-preview-02-05\"  # @param {type: \"string\"}"
      ],
      "metadata": {
        "id": "cNN5QPS7N9_w"
      },
      "id": "cNN5QPS7N9_w",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Safety Filters\n",
        "\n",
        "The Gemini API provides safety filters that you can adjust across multiple filter categories to restrict or allow certain types of content. You can use these filters to adjust what's appropriate for your use case. See the Configure safety filters page for details.\n",
        "\n",
        "When you make a request to Gemini, the content is analyzed and assigned a safety rating. You can inspect the safety ratings of the generated content by printing out the model responses."
      ],
      "metadata": {
        "id": "sBZR_3KjOK4_"
      },
      "id": "sBZR_3KjOK4_"
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        threshold=\"BLOCK_LOW_AND_ABOVE\",\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "KRSiNsU8OBqt"
      },
      "id": "KRSiNsU8OBqt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure model parameters\n",
        "\n",
        "You can include parameter values in each call that you send to a model to control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change.\n",
        "\n",
        "- Learn more about [experimenting with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values).\n",
        "\n",
        "- See a list of all [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#parameters)."
      ],
      "metadata": {
        "id": "gypJtAXLOPy1"
      },
      "id": "gypJtAXLOPy1"
    },
    {
      "cell_type": "code",
      "source": [
        "generate_content_config=GenerateContentConfig(\n",
        "        temperature=0.3,\n",
        "        top_p=0.95,\n",
        "        top_k=20,\n",
        "        max_output_tokens=4096,\n",
        "        safety_settings=safety_settings\n",
        "    )"
      ],
      "metadata": {
        "id": "3uiMVDK-OU9Z"
      },
      "id": "3uiMVDK-OU9Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the YouTube Video URL"
      ],
      "metadata": {
        "id": "AqIJj7MPOVlD"
      },
      "id": "AqIJj7MPOVlD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide link to a public YouTube video\n",
        "YOUTUBE_VIDEO_URL = \"https://www.youtube.com/watch?v=8peKcSEDFB4\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "youtube_video_embed_url = YOUTUBE_VIDEO_URL.replace(\"/watch?v=\", \"/embed/\")\n",
        "\n",
        "# Create HTML code to directly embed video\n",
        "youtube_video_embed_html_code = f\"\"\"\n",
        "<iframe width=\"560\" height=\"315\" src=\"{youtube_video_embed_url}\"\n",
        "title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay;\n",
        "clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
        "</iframe>\n",
        "\"\"\"\n",
        "\n",
        "# Display embedded YouTube video\n",
        "display(HTML(youtube_video_embed_html_code))"
      ],
      "metadata": {
        "id": "dyQxZZViOchD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "93669cb3-6856-4c00-8242-443e9b352873"
      },
      "id": "dyQxZZViOchD",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/8peKcSEDFB4\"\n",
              "title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay;\n",
              "clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
              "</iframe>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarize the YT video\n",
        "\n",
        "Short summary of what is happening in the video"
      ],
      "metadata": {
        "id": "_YQoM3LjbI7n"
      },
      "id": "_YQoM3LjbI7n"
    },
    {
      "cell_type": "code",
      "source": [
        "# Call Gemini API with prompt to summarize the video\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the video\n",
        "\"\"\"\n",
        "\n",
        "yt_video = Part.from_uri(\n",
        "    file_uri= YOUTUBE_VIDEO_URL,\n",
        "    mime_type=\"video/mp4\",\n",
        ")\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model= MODEL_ID,\n",
        "    config = generate_content_config,\n",
        "    contents=[\n",
        "        yt_video,\n",
        "        prompt\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "j8gw35WubRlr",
        "outputId": "ae000684-1975-4a66-c4ac-f50441abf2f7"
      },
      "id": "j8gw35WubRlr",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sure, here's a summary of the video:\n\nThe video is a commercial for Hyundai. It begins with a man looking at a sign that says \"2022 World Car of the Year, Search Hyundai\". He then uses voice search on his phone to search for \"Hyundai\". The video then shows a series of people mispronouncing the name \"Hyundai\" in different ways, and then the correct pronunciation is revealed. The video ends with a shot of a Hyundai car."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify the commercial entities\n",
        "\n",
        "Identify all the commercial entities appearing in the video along with the timestamps"
      ],
      "metadata": {
        "id": "aXtystoqbk9i"
      },
      "id": "aXtystoqbk9i"
    },
    {
      "cell_type": "code",
      "source": [
        "# Call Gemini API with prompt to identify the commercial entities appearing and record their timestamps.\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Analyze the video and:\n",
        "1. List all unique commercial entities present.\n",
        "2. Generate a markdown table \"TimeOnScreen\" with columns \"Entity,\" \"TimeOnScreenStart\" (seconds),\n",
        "and \"TimeOnScreenEnd\" (seconds). Each entity appearance should have its own row.\n",
        "3. Timestamp Justification:  For each timestamp in the \"TimeOnScreen\" table,\n",
        "briefly explain your reasoning.  For example, \"TimeOnScreenStart: 15 seconds\n",
        "- Logo appears in the top right corner.\"\n",
        "\"\"\"\n",
        "\n",
        "yt_video = Part.from_uri(\n",
        "    file_uri= YOUTUBE_VIDEO_URL,\n",
        "    mime_type=\"video/mp4\",\n",
        ")\n",
        "\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model= MODEL_ID,\n",
        "    config = generate_content_config,\n",
        "    contents=[\n",
        "        yt_video,\n",
        "        prompt\n",
        "    ],\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "Smr3L7kETri9",
        "outputId": "a3de44b3-a525-4aa4-83f5-157b5286411d"
      },
      "id": "Smr3L7kETri9",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's the analysis of the video:\n\n**1. Unique Commercial Entities:**\n\n*   Hyundai\n*   High 'n' Dye\n*   Hawaiian Tie\n*   High End Pie\n*   Highland Eye\n\n**2. TimeOnScreen Table:**\n\n| Entity          | TimeOnScreenStart (seconds) | TimeOnScreenEnd (seconds) |\n|-----------------|---------------------------|-------------------------|\n| Hyundai         | 0                         | 1                       |\n| Hyundai         | 1                         | 1                       |\n| High 'n' Dye   | 5                         | 8                       |\n| Hyundai         | 24                        | 29                      |\n| Hawaiian Tie    | 10                        | 11                      |\n| High End Pie    | 15                        | 16                      |\n| Highland Eye    | 19                        | 20                      |\n| Hyundai         | 27                        | 29                      |\n\n**3. Timestamp Justification:**\n\n*   **Hyundai, 0-1 seconds:** The Hyundai logo appears on the advertisement.\n*   **Hyundai, 1-1 seconds:** The Hyundai logo appears on the advertisement.\n*   **High 'n' Dye, 5-8 seconds:** The storefront of \"High 'n' Dye\" is shown.\n*   **Hyundai, 24-29 seconds:** The Hyundai car is shown, and the Hyundai logo appears on the screen.\n*   **Hawaiian Tie, 10-11 seconds:** The storefront of \"Hawaiian Tie\" is shown.\n*   **High End Pie, 15-16 seconds:** The food truck \"High End Pie\" is shown.\n*   **Highland Eye, 19-20 seconds:** The storefront of \"Highland Eye\" is shown.\n*   **Hyundai, 27-29 seconds:** The Hyundai logo appears on the screen."
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "ai_camp_uc2_yt_analysis"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}